{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.12.4\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ultralytics\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "from queue import Queue\n",
    "from threading import Thread\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from abc import ABC, abstractmethod\n",
    "import json\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import List, Dict, Any, Tuple, Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce GTX 1650'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "YOLO_MODEL_PATH = \"models/yolo/yolov8n.pt\"\n",
    "YOLO_CONFIDENCE_THRESHOLD = 0.5\n",
    "MAX_QUEUE_SIZE = 30\n",
    "# Class indices for person, car, truck, bus, and motorcycle in COCO dataset\n",
    "TARGET_CLASSES = [0, 2, 7, 5, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_VIDEO_PATH = \"data/videos/Rec16-1_trimmed.mp4\"\n",
    "# OUTPUT_VIDEO_PATH = \"output/videos/Rec16-1-yolo_trimmed_final.mp4\"\n",
    "INPUT_TIMESTAMP_PATH = \"output/timestamps/Rec16-1_trimmed.txt\"\n",
    "# JSON_OUTPUT_PATH = \"output/json/Rec16-1_trimmed_yolo_final.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class VideoInfo:\n",
    "    width: int\n",
    "    height: int\n",
    "    fps: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ProcessConfig:\n",
    "    input_path: str\n",
    "    video_id: str\n",
    "    timestamps_path: str\n",
    "    max_queue_size: int\n",
    "    output_dir: str\n",
    "    output_video_path: str\n",
    "    output_json_path: str\n",
    "    total_frames: int = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class YOLOConfig:\n",
    "    model_path: str\n",
    "    confidence_threshold: float\n",
    "    target_classes: List[int]\n",
    "    model: Any\n",
    "    timestamps: List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class YOLOProcessConfig:\n",
    "    # Fields from ProcessConfig\n",
    "    input_path: str\n",
    "    video_id: str\n",
    "    timestamps_path: str\n",
    "    max_queue_size: int\n",
    "    output_dir: str\n",
    "    output_video_path: str\n",
    "    output_json_path: str\n",
    "    total_frames: int = 0\n",
    "    \n",
    "    # YOLO-specific field\n",
    "    yolo_config: YOLOConfig = field(default_factory=dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgressTracker:\n",
    "    def __init__(self, total, desc):\n",
    "        self.total = total\n",
    "        self.desc = desc\n",
    "        self.lock = threading.Lock()\n",
    "        self.pbar = None\n",
    "\n",
    "    def start(self):\n",
    "        self.pbar = tqdm(total=self.total, desc=self.desc, position=1, leave=False)\n",
    "\n",
    "    def update(self, n=1):\n",
    "        with self.lock:\n",
    "            if self.pbar:\n",
    "                self.pbar.update(n)\n",
    "\n",
    "    def close(self):\n",
    "        if self.pbar:\n",
    "            self.pbar.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FileIO:\n",
    "    @staticmethod\n",
    "    def read_lines(file_path: str) -> List[str]:\n",
    "        with open(file_path, 'r') as f:\n",
    "            return [line.strip() for line in f]\n",
    "\n",
    "    @staticmethod\n",
    "    def read_json(file_path: str) -> Dict[str, Any]:\n",
    "        with open(file_path, 'r') as f:\n",
    "            return json.load(f)\n",
    "\n",
    "    @staticmethod\n",
    "    def write_json(file_path: str, data: Dict[str, Any]):\n",
    "        with open(file_path, 'w') as f:\n",
    "            json.dump(data, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoProcessor(ABC):\n",
    "    def __init__(self, output_dir: str, default_max_queue_size: int = 30, max_workers: int = None):\n",
    "        self.output_dir = output_dir\n",
    "        self.default_max_queue_size = default_max_queue_size\n",
    "        self.max_workers = max_workers\n",
    "        self.text_reader = FileIO()\n",
    "\n",
    "    @abstractmethod\n",
    "    def create_process_config(self, video_config: Dict[str, Any]) -> Any:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def _process_frames(self, frame_queue: Queue, result_queue: Queue, process_config: Any, results_dict: Dict[str, Any], progress_callback: Callable[[int], None]):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def _post_process(self, result_queue: Queue, output_queue: Queue, progress_callback: Callable[[int], None]):\n",
    "        pass\n",
    "\n",
    "    def process_single_video(self, process_config: Any, pbar: tqdm):\n",
    "        cap, video_info = self._initialize_video_capture(process_config.input_path)\n",
    "        process_config.total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        queues = self._create_queues(process_config.max_queue_size)\n",
    "        results_dict: Dict[str, Any] = {}\n",
    "\n",
    "        pbar.total = process_config.total_frames\n",
    "        pbar.set_description(f\"Processing {process_config.video_id}\")\n",
    "        pbar.reset()\n",
    "\n",
    "        def progress_callback(n):\n",
    "            pbar.update(n)\n",
    "\n",
    "        threads = self._create_and_start_threads(cap, queues, process_config, results_dict, video_info, progress_callback)\n",
    "        self._join_threads(threads)\n",
    "\n",
    "        self._save_results(process_config.output_json_path, results_dict)\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # def process_videos(self, video_configs: List[Dict[str, Any]]):\n",
    "    #     with tqdm(total=len(video_configs), desc=\"Processing videos\", position=0, leave=True) as pbar:\n",
    "    #         with ThreadPoolExecutor(max_workers=self.max_workers) as executor:\n",
    "    #             futures = [executor.submit(self.process_single_video, self.create_process_config(video_config)) \n",
    "    #                        for video_config in video_configs]\n",
    "    #             for future in as_completed(futures):\n",
    "    #                 try:\n",
    "    #                     future.result()\n",
    "    #                     pbar.update(1)\n",
    "    #                 except Exception as e:\n",
    "    #                     print(f\"An error occurred: {str(e)}\")\n",
    "    def process_videos(self, video_configs: List[Dict[str, Any]]):\n",
    "        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:\n",
    "            futures = []\n",
    "            progress_bars = []\n",
    "            \n",
    "            for video_config in video_configs:\n",
    "                config = self.create_process_config(video_config)\n",
    "                pbar = tqdm(total=0, desc=f\"Initializing {config.video_id}\", position=len(progress_bars), leave=True)\n",
    "                progress_bars.append(pbar)\n",
    "                futures.append(executor.submit(self.process_single_video, config, pbar))\n",
    "            \n",
    "            for future in as_completed(futures):\n",
    "                try:\n",
    "                    future.result()\n",
    "                except Exception as e:\n",
    "                    print(f\"An error occurred: {str(e)}\")\n",
    "            \n",
    "            for pbar in progress_bars:\n",
    "                pbar.close()\n",
    "\n",
    "    def _initialize_video_capture(self, input_path: str) -> Tuple[cv2.VideoCapture, VideoInfo]:\n",
    "        cap = cv2.VideoCapture(input_path)\n",
    "        video_info = VideoInfo(\n",
    "            width=int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
    "            height=int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)),\n",
    "            fps=int(cap.get(cv2.CAP_PROP_FPS))\n",
    "        )\n",
    "        return cap, video_info\n",
    "\n",
    "    def _create_queues(self, max_queue_size: int) -> Dict[str, Queue]:\n",
    "        return {\n",
    "            'frame': Queue(maxsize=max_queue_size),\n",
    "            'result': Queue(maxsize=max_queue_size),\n",
    "            'output': Queue(maxsize=max_queue_size)\n",
    "        }\n",
    "\n",
    "    def _create_and_start_threads(self, cap: cv2.VideoCapture, queues: Dict[str, Queue], \n",
    "                                  process_config: Any, results_dict: Dict[str, Any], \n",
    "                                  video_info: VideoInfo, progress_callback: Callable[[int], None]) -> List[Thread]:\n",
    "        threads = [\n",
    "            Thread(target=self._read_frames, args=(cap, queues['frame'], process_config.max_queue_size)),\n",
    "            Thread(target=self._process_frames, args=(queues['frame'], queues['result'], process_config, results_dict, progress_callback)),\n",
    "            Thread(target=self._post_process, args=(queues['result'], queues['output'], progress_callback)),\n",
    "            Thread(target=self._write_video, args=(process_config.output_video_path, queues['output'], \n",
    "                                                   video_info.fps, video_info.width, video_info.height))\n",
    "        ]\n",
    "        for thread in threads:\n",
    "            thread.start()\n",
    "        return threads\n",
    "\n",
    "\n",
    "    def _join_threads(self, threads: List[Thread]):\n",
    "        for thread in threads:\n",
    "            thread.join()\n",
    "\n",
    "    def _read_frames(self, cap: cv2.VideoCapture, frame_queue: Queue, max_queue_size: int):\n",
    "        while True:\n",
    "            if frame_queue.qsize() < max_queue_size:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                frame_queue.put(frame)\n",
    "            else:\n",
    "                time.sleep(0.1)\n",
    "        frame_queue.put(None)\n",
    "\n",
    "    def _write_video(self, output_path: str, output_queue: Queue, fps: int, width: int, height: int):\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "        \n",
    "        while True:\n",
    "            frame = output_queue.get()\n",
    "            if frame is None:\n",
    "                break\n",
    "            out.write(cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n",
    "        \n",
    "        out.release()\n",
    "\n",
    "    def _save_results(self, output_json_path: str, results_dict: Dict[str, Any]):\n",
    "        self.text_reader.write_json(output_json_path, results_dict)\n",
    "    \n",
    "    def get_unique_output_dir(self, base_path: str) -> str:\n",
    "        if not os.path.exists(base_path):\n",
    "            return base_path\n",
    "        \n",
    "        counter = 1\n",
    "        while True:\n",
    "            new_path = f\"{base_path}_copy{counter}\"\n",
    "            if not os.path.exists(new_path):\n",
    "                return new_path\n",
    "            counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLOProcessor(VideoProcessor):\n",
    "    def __init__(self, output_dir: str, default_yolo_model_path: str = YOLO_MODEL_PATH, \n",
    "                 default_confidence_threshold: float = YOLO_CONFIDENCE_THRESHOLD, \n",
    "                 default_target_classes: List[int] = TARGET_CLASSES,\n",
    "                 default_max_queue_size: int = MAX_QUEUE_SIZE, max_workers: int = None):\n",
    "        super().__init__(output_dir, default_max_queue_size, max_workers)\n",
    "        self.default_yolo_model_path = default_yolo_model_path\n",
    "        self.default_confidence_threshold = default_confidence_threshold\n",
    "        self.default_target_classes = default_target_classes\n",
    "        self.yolo_models: Dict[str, Any] = {}\n",
    "\n",
    "    def get_yolo_model(self, model_path: str) -> Any:\n",
    "        if model_path not in self.yolo_models:\n",
    "            self.yolo_models[model_path] = YOLO(model_path)\n",
    "        return self.yolo_models[model_path]\n",
    "\n",
    "    def create_process_config(self, video_config: Dict[str, Any]) -> YOLOProcessConfig:\n",
    "        base_config = self._create_base_config(video_config)\n",
    "        output_paths = self._create_output_paths(base_config)\n",
    "        yolo_config = self._create_yolo_config(video_config)\n",
    "        \n",
    "        return YOLOProcessConfig(\n",
    "            input_path=base_config.input_path,\n",
    "            video_id=base_config.video_id,\n",
    "            timestamps_path=base_config.timestamps_path,\n",
    "            max_queue_size=base_config.max_queue_size,\n",
    "            output_dir=output_paths['output_dir'],\n",
    "            output_video_path=output_paths['output_video_path'],\n",
    "            output_json_path=output_paths['output_json_path'],\n",
    "            total_frames=0,  # Will be set later\n",
    "            yolo_config=yolo_config\n",
    "        )\n",
    "\n",
    "    def _create_base_config(self, video_config: Dict[str, Any]) -> ProcessConfig:\n",
    "        return ProcessConfig(\n",
    "            input_path=video_config['input_path'],\n",
    "            video_id=video_config['video_id'],\n",
    "            timestamps_path=video_config['timestamps_path'],\n",
    "            max_queue_size=video_config.get('max_queue_size', self.default_max_queue_size),\n",
    "            output_dir='',  # Will be set in _create_output_paths\n",
    "            output_video_path='',  # Will be set in _create_output_paths\n",
    "            output_json_path='',  # Will be set in _create_output_paths\n",
    "            total_frames=0  # Will be set later\n",
    "        )\n",
    "\n",
    "    def _create_output_paths(self, config: ProcessConfig) -> Dict[str, str]:\n",
    "        base_output_dir = os.path.join(self.output_dir, config.video_id)\n",
    "        output_dir = self.get_unique_output_dir(base_output_dir)\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        return {\n",
    "            'output_dir': output_dir,\n",
    "            'output_video_path': os.path.join(output_dir, f\"output_{config.video_id}.mp4\"),\n",
    "            'output_json_path': os.path.join(output_dir, f\"output_{config.video_id}.json\"),\n",
    "        }\n",
    "\n",
    "    def _create_yolo_config(self, video_config: Dict[str, Any]) -> YOLOConfig:\n",
    "        yolo_model_path = video_config.get('yolo_model_path', self.default_yolo_model_path)\n",
    "        model = self.get_yolo_model(yolo_model_path)\n",
    "        \n",
    "        # Disable console output for the model\n",
    "        model.verbose = False\n",
    "        \n",
    "        return YOLOConfig(\n",
    "            model_path=yolo_model_path,\n",
    "            confidence_threshold=video_config.get('confidence_threshold', self.default_confidence_threshold),\n",
    "            target_classes=video_config.get('target_classes', self.default_target_classes),\n",
    "            model=model,\n",
    "            timestamps=self.text_reader.read_lines(video_config['timestamps_path'])\n",
    "        )\n",
    "\n",
    "    def _process_frames(self, frame_queue: Queue, result_queue: Queue, process_config: YOLOProcessConfig, results_dict: Dict[str, Any], progress_callback: Callable[[int], None]):\n",
    "        frame_index = 0\n",
    "        while True:\n",
    "            frame = frame_queue.get()\n",
    "            if frame is None:\n",
    "                break\n",
    "            \n",
    "            results = self._run_yolo_inference(frame, process_config.yolo_config)\n",
    "            frame_results = self._process_yolo_results(results, process_config.yolo_config.model)\n",
    "            \n",
    "            timestamp = self._get_timestamp(frame_index, process_config.yolo_config.timestamps)\n",
    "            results_dict[timestamp] = frame_results\n",
    "            result_queue.put((frame, results))\n",
    "            frame_index += 1\n",
    "            progress_callback(1)  # Update progress by 1 frame\n",
    "        \n",
    "        result_queue.put(None)\n",
    "\n",
    "    def _run_yolo_inference(self, frame: np.ndarray, yolo_config: YOLOConfig) -> Any:\n",
    "        return yolo_config.model(frame,\n",
    "                                 classes=yolo_config.target_classes,\n",
    "                                 conf=yolo_config.confidence_threshold, verbose=False)\n",
    "\n",
    "    def _process_yolo_results(self, results: Any, yolo_model: Any) -> List[Dict[str, Any]]:\n",
    "        frame_results = []\n",
    "        for det in results[0].boxes.data:\n",
    "            x1, y1, x2, y2, conf, cls = det.tolist()\n",
    "            frame_results.append({\n",
    "                \"class\": yolo_model.names[int(cls)],\n",
    "                \"confidence\": conf,\n",
    "                \"bbox\": [x1, y1, x2, y2]\n",
    "            })\n",
    "        return frame_results\n",
    "\n",
    "    def _get_timestamp(self, frame_index: int, timestamps: List[str]) -> str:\n",
    "        return timestamps[frame_index] if frame_index < len(timestamps) else f\"frame_{frame_index}\"\n",
    "\n",
    "    def _post_process(self, result_queue: Queue, output_queue: Queue, progress_callback: Callable[[int], None]):\n",
    "        while True:\n",
    "            item = result_queue.get()\n",
    "            if item is None:\n",
    "                break\n",
    "            frame, results = item\n",
    "            annotated_frame = results[0].plot()\n",
    "            output_queue.put(annotated_frame)\n",
    "            # We don't update progress here anymore\n",
    "        \n",
    "        output_queue.put(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = \"output\"\n",
    "yolo_processor = YOLOProcessor(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rec16-1_trimmed:   0%|          | 0/1396 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.87 🚀 Python-3.12.4 torch-2.4.0+cu121 CUDA:0 (NVIDIA GeForce GTX 1650, 3897MiB)\n",
      "YOLOv8n summary (fused): 168 layers, 3,151,904 parameters, 0 gradients, 8.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rec16-1_trimmed: 100%|██████████| 1396/1396 [00:33<00:00, 42.23it/s]\n",
      "Processing Rec16-2_trimmed: 100%|██████████| 1396/1396 [00:33<00:00, 42.23it/s]\n"
     ]
    }
   ],
   "source": [
    "video_config = [\n",
    "    {\n",
    "        \"video_id\": \"Rec16-1_trimmed\",\n",
    "        \"input_path\": INPUT_VIDEO_PATH,\n",
    "        \"timestamps_path\": INPUT_TIMESTAMP_PATH\n",
    "    },\n",
    "    {\n",
    "        \"video_id\": \"Rec16-2_trimmed\",\n",
    "        \"input_path\": INPUT_VIDEO_PATH,\n",
    "        \"timestamps_path\": INPUT_TIMESTAMP_PATH\n",
    "    }\n",
    "]\n",
    "\n",
    "yolo_processor.process_videos(video_config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
