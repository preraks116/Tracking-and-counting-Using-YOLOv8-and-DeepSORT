{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.12.4\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ultralytics\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "from queue import Queue\n",
    "from threading import Thread\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from abc import ABC, abstractmethod\n",
    "import json\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import os\n",
    "from typing import Dict, Any, Tuple, List\n",
    "import logging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce GTX 1650'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['person', 'bicycle', 'car', 'motorcycle',\n",
    "               'airplane', 'bus', 'train', 'truck', 'boat',\n",
    "               'traffic light', 'fire hydrant', 'stop sign',\n",
    "               'parking meter', 'bench', 'bird', 'cat', 'dog',\n",
    "               'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra',\n",
    "               'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n",
    "               'suitcase', 'frisbee', 'skis', 'snowboard',\n",
    "               'sports ball', 'kite', 'baseball bat', 'baseball glove',\n",
    "               'skateboard', 'surfboard', 'tennis racket', 'bottle',\n",
    "               'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',\n",
    "               'banana', 'apple', 'sandwich', 'orange', 'broccoli',\n",
    "               'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair',\n",
    "               'couch', 'potted plant', 'bed', 'dining table', 'toilet',\n",
    "               'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
    "               'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book',\n",
    "               'clock', 'vase', 'scissors', 'teddy bear', 'hair drier',\n",
    "               'toothbrush']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FileIO:\n",
    "    @staticmethod\n",
    "    def read_lines(file_path):\n",
    "        with open(file_path, 'r') as f:\n",
    "            return [line.strip() for line in f]\n",
    "\n",
    "    @staticmethod\n",
    "    def read_json(file_path):\n",
    "        with open(file_path, 'r') as f:\n",
    "            return json.load(f)\n",
    "\n",
    "    @staticmethod\n",
    "    def write_json(file_path, data):\n",
    "        with open(file_path, 'w') as f:\n",
    "            json.dump(data, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoProcessor(ABC):\n",
    "    def __init__(self, output_dir, max_queue_size=30, max_workers=None):\n",
    "        self.output_dir = output_dir\n",
    "        self.max_queue_size = max_queue_size\n",
    "        self.max_workers = max_workers\n",
    "        self.text_reader = FileIO()\n",
    "\n",
    "    @abstractmethod\n",
    "    def create_process_config(self, video_config):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def _process_frames(self, frame_queue, result_queue, process_config, results_dict):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def _post_process(self, result_queue, output_queue):\n",
    "        pass\n",
    "\n",
    "    def process_videos(self, video_configs):\n",
    "        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:\n",
    "            futures = [executor.submit(self.process_single_video, self.create_process_config(video_config)) \n",
    "                       for video_config in video_configs]\n",
    "            for future in as_completed(futures):\n",
    "                try:\n",
    "                    future.result()\n",
    "                except Exception as e:\n",
    "                    print(f\"An error occurred: {str(e)}\")\n",
    "\n",
    "    def process_single_video(self, process_config):\n",
    "        cap, video_params = self._initialize_video_capture(process_config['input_path'])\n",
    "        queues = self._create_queues()\n",
    "        results_dict = {}\n",
    "\n",
    "        threads = self._create_and_start_threads(cap, queues, process_config, results_dict, video_params)\n",
    "        self._join_threads(threads)\n",
    "        self._save_results(process_config['output_json_path'], results_dict)\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    def _initialize_video_capture(self, input_path):\n",
    "        cap = cv2.VideoCapture(input_path)\n",
    "        video_params = {\n",
    "            'width': int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
    "            'height': int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)),\n",
    "            'fps': int(cap.get(cv2.CAP_PROP_FPS))\n",
    "        }\n",
    "        return cap, video_params\n",
    "\n",
    "    def _create_queues(self):\n",
    "        return {name: Queue(maxsize=self.max_queue_size) for name in ['frame', 'result', 'output']}\n",
    "\n",
    "    def _create_and_start_threads(self, cap, queues, process_config, results_dict, video_params):\n",
    "        threads = [\n",
    "            Thread(target=self._read_frames, args=(cap, queues['frame'])),\n",
    "            Thread(target=self._process_frames, args=(queues['frame'], queues['result'], process_config, results_dict)),\n",
    "            Thread(target=self._post_process, args=(queues['result'], queues['output'])),\n",
    "            Thread(target=self._write_video, args=(process_config['output_video_path'], queues['output'], \n",
    "                                                   video_params['fps'], video_params['width'], video_params['height']))\n",
    "        ]\n",
    "        for thread in threads:\n",
    "            thread.start()\n",
    "        return threads\n",
    "\n",
    "    def _join_threads(self, threads):\n",
    "        for thread in threads:\n",
    "            thread.join()\n",
    "\n",
    "    def _save_results(self, output_json_path, results_dict):\n",
    "        self.text_reader.write_json(output_json_path, results_dict)\n",
    "\n",
    "    def _read_frames(self, cap, frame_queue):\n",
    "        while True:\n",
    "            if frame_queue.qsize() < self.max_queue_size:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                frame_queue.put(frame)\n",
    "            else:\n",
    "                time.sleep(0.1)\n",
    "        frame_queue.put(None)\n",
    "\n",
    "    def _write_video(self, output_path, output_queue, fps, width, height):\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "        \n",
    "        while True:\n",
    "            frame = output_queue.get()\n",
    "            if frame is None:\n",
    "                break\n",
    "            out.write(cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n",
    "        \n",
    "        out.release()\n",
    "\n",
    "    def get_unique_output_dir(self, base_path):\n",
    "        if not os.path.exists(base_path):\n",
    "            return base_path\n",
    "        \n",
    "        counter = 1\n",
    "        while True:\n",
    "            new_path = f\"{base_path}_copy{counter}\"\n",
    "            if not os.path.exists(new_path):\n",
    "                return new_path\n",
    "            counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "# import pytesseract\n",
    "# import re\n",
    "# from queue import Queue\n",
    "# from threading import Thread\n",
    "# from typing import Dict, Any, Tuple\n",
    "\n",
    "# class OCRProcessor(VideoProcessor):\n",
    "#     def __init__(self, output_dir: str, timestamp_region: Tuple[int, int, int, int],\n",
    "#                  max_queue_size: int = 30, max_workers: int = None):\n",
    "#         super().__init__(output_dir, max_queue_size, max_workers)\n",
    "#         self.timestamp_region = timestamp_region\n",
    "\n",
    "#     def create_process_config(self, video_config: Dict[str, Any]) -> Dict[str, Any]:\n",
    "#         base_output_dir = os.path.join(self.output_dir, video_config['video_id'])\n",
    "#         output_dir = self.get_unique_output_dir(base_output_dir)\n",
    "#         os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "#         return {\n",
    "#             'input_path': video_config['input_path'],\n",
    "#             'video_id': video_config['video_id'],\n",
    "#             'output_dir': output_dir,\n",
    "#             'output_video_path': os.path.join(output_dir, f\"output_{video_config['video_id']}.mp4\"),\n",
    "#             'output_json_path': os.path.join(output_dir, f\"output_{video_config['video_id']}.json\"),\n",
    "#             'output_txt_path': os.path.join(output_dir, f\"timestamps_{video_config['video_id']}.txt\"),\n",
    "#         }\n",
    "\n",
    "#     def _process_frames(self, frame_queue: Queue, result_queue: Queue, process_config: Dict[str, Any], results_dict: Dict[str, Any]):\n",
    "#         prev_timestamp = None\n",
    "#         frame_index = 0\n",
    "\n",
    "#         while True:\n",
    "#             frame = frame_queue.get()\n",
    "#             if frame is None:\n",
    "#                 break\n",
    "\n",
    "#             x1, y1, x2, y2 = self.timestamp_region\n",
    "#             timestamp_img = frame[y1:y2, x1:x2]\n",
    "\n",
    "#             gray = cv2.cvtColor(timestamp_img, cv2.COLOR_BGR2GRAY)\n",
    "#             thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "#             timestamp = pytesseract.image_to_string(thresh, config='--psm 7').strip()\n",
    "\n",
    "#             if timestamp != prev_timestamp:\n",
    "#                 cleaned_timestamp = re.sub(r'[^\\d]', '', timestamp)\n",
    "#                 results_dict[cleaned_timestamp] = frame_index\n",
    "#                 result_queue.put((cleaned_timestamp, frame))\n",
    "#                 prev_timestamp = timestamp\n",
    "\n",
    "#             frame_index += 1\n",
    "\n",
    "#         result_queue.put(None)\n",
    "\n",
    "#     def _post_process(self, result_queue: Queue, output_queue: Queue):\n",
    "#         frame_count = 0\n",
    "#         timestamps = []\n",
    "\n",
    "#         while True:\n",
    "#             item = result_queue.get()\n",
    "#             if item is None:\n",
    "#                 break\n",
    "\n",
    "#             timestamp, frame = item\n",
    "#             timestamps.append(timestamp)\n",
    "#             output_queue.put(frame)\n",
    "#             frame_count += 1\n",
    "\n",
    "#             if frame_count % 100 == 0:\n",
    "#                 print(f\"Processed {frame_count} unique frames\")\n",
    "\n",
    "#         output_queue.put(None)\n",
    "#         return timestamps\n",
    "\n",
    "#     def process_video(self, process_config: Dict[str, Any]):\n",
    "#         cap, video_info = self._initialize_video_capture(process_config['input_path'])\n",
    "#         results_dict = {}\n",
    "\n",
    "#         self.threads = self._create_threads(cap, process_config, results_dict, video_info)\n",
    "#         self._start_threads()\n",
    "#         timestamps = self._join_threads()\n",
    "\n",
    "#         self._save_results(process_config['output_json_path'], results_dict)\n",
    "#         self._save_timestamps(process_config['output_txt_path'], timestamps)\n",
    "\n",
    "#         cap.release()\n",
    "#         cv2.destroyAllWindows()\n",
    "\n",
    "#         print(f\"Video processing complete. {len(results_dict)} unique frames extracted.\")\n",
    "#         print(f\"Output video saved to: {process_config['output_video_path']}\")\n",
    "#         print(f\"Timestamps saved to: {process_config['output_txt_path']}\")\n",
    "\n",
    "#     def _save_timestamps(self, output_path: str, timestamps: List[str]):\n",
    "#         with open(output_path, 'w') as f:\n",
    "#             for timestamp in timestamps:\n",
    "#                 f.write(f\"{timestamp}\\n\")\n",
    "\n",
    "#     def _create_threads(self, cap: cv2.VideoCapture, process_config: Dict[str, Any],\n",
    "#                         results_dict: Dict[str, Any], video_info: Dict[str, int]) -> List[Thread]:\n",
    "#         return [\n",
    "#             Thread(target=self._read_frames, args=(cap,)),\n",
    "#             Thread(target=self._process_frames, args=(self.queues['frame'], self.queues['result'], process_config, results_dict)),\n",
    "#             Thread(target=self._post_process, args=(self.queues['result'], self.queues['output'])),\n",
    "#             Thread(target=self._write_video, args=(process_config['output_video_path'], video_info['fps'], video_info['width'], video_info['height']))\n",
    "#         ]\n",
    "\n",
    "#     def _join_threads(self) -> List[str]:\n",
    "#         timestamps = None\n",
    "#         for thread in self.threads:\n",
    "#             if thread._target == self._post_process:\n",
    "#                 timestamps = thread.join()\n",
    "#             else:\n",
    "#                 thread.join()\n",
    "#         return timestamps\n",
    "\n",
    "#     def _write_video(self, output_path: str, fps: int, width: int, height: int):\n",
    "#         fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "#         out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "#         while True:\n",
    "#             frame = self.queues['output'].get()\n",
    "#             if frame is None:\n",
    "#                 break\n",
    "#             out.write(frame)\n",
    "\n",
    "#         out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "from typing import Callable\n",
    "import os\n",
    "\n",
    "import re\n",
    "from queue import Queue\n",
    "from typing import Dict, Any, Tuple, List\n",
    "\n",
    "class OCRProcessor(VideoProcessor):\n",
    "    def __init__(self, output_dir: str, timestamp_region: Tuple[int, int, int, int],\n",
    "                 max_queue_size: int = 30, max_workers: int = None):\n",
    "        super().__init__(output_dir, max_queue_size, max_workers)\n",
    "        self.timestamp_region = timestamp_region\n",
    "\n",
    "    def create_process_config(self, video_config: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        base_output_dir = os.path.join(self.output_dir, video_config['video_id'])\n",
    "        output_dir = self.get_unique_output_dir(base_output_dir)\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        return {\n",
    "            'input_path': video_config['input_path'],\n",
    "            'video_id': video_config['video_id'],\n",
    "            'output_dir': output_dir,\n",
    "            'output_video_path': os.path.join(output_dir, f\"output_{video_config['video_id']}.mp4\"),\n",
    "            'output_json_path': os.path.join(output_dir, f\"output_{video_config['video_id']}.json\"),\n",
    "            'output_txt_path': os.path.join(output_dir, f\"timestamps_{video_config['video_id']}.txt\"),\n",
    "        }\n",
    "\n",
    "    def _process_frames(self, frame_queue: Queue, result_queue: Queue, \n",
    "                        process_config: Dict[str, Any], results_dict: Dict[str, Any]):\n",
    "        prev_timestamp = None\n",
    "        frame_index = 0\n",
    "\n",
    "        while True:\n",
    "            frame = frame_queue.get()\n",
    "            if frame is None:\n",
    "                break\n",
    "\n",
    "            x1, y1, x2, y2 = self.timestamp_region\n",
    "            timestamp_img = frame[y1:y2, x1:x2]\n",
    "\n",
    "            gray = cv2.cvtColor(timestamp_img, cv2.COLOR_BGR2GRAY)\n",
    "            thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "            timestamp = pytesseract.image_to_string(thresh, config='--psm 7').strip()\n",
    "\n",
    "            if timestamp != prev_timestamp:\n",
    "                cleaned_timestamp = re.sub(r'[^\\d]', '', timestamp)\n",
    "                results_dict[cleaned_timestamp] = frame_index\n",
    "                result_queue.put((cleaned_timestamp, frame))\n",
    "                prev_timestamp = timestamp\n",
    "\n",
    "            frame_index += 1\n",
    "\n",
    "        result_queue.put(None)\n",
    "\n",
    "    def _post_process(self, result_queue: Queue, output_queue: Queue) -> List[str]:\n",
    "        frame_count = 0\n",
    "        timestamps = []\n",
    "\n",
    "        while True:\n",
    "            item = result_queue.get()\n",
    "            if item is None:\n",
    "                break\n",
    "\n",
    "            timestamp, frame = item\n",
    "            timestamps.append(timestamp)\n",
    "            output_queue.put(frame)\n",
    "            frame_count += 1\n",
    "\n",
    "            if frame_count % 100 == 0:\n",
    "                print(f\"Processed {frame_count} unique frames\")\n",
    "\n",
    "        output_queue.put(None)\n",
    "        return timestamps\n",
    "\n",
    "    def _write_video(self, output_path: str, output_queue: Queue, video_info: Dict[str, int]):\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(output_path, fourcc, video_info['fps'],\n",
    "                            (video_info['width'], video_info['height']))\n",
    "\n",
    "        while True:\n",
    "            frame = output_queue.get()\n",
    "            if frame is None:\n",
    "                break\n",
    "            out.write(cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "        out.release()\n",
    "\n",
    "    def process_single_video(self, process_config: Dict[str, Any]):\n",
    "        cap, video_info = self._initialize_video_capture(process_config['input_path'])\n",
    "        queues = self._create_queues()\n",
    "        results_dict: Dict[str, Any] = {}\n",
    "\n",
    "        threads = self._create_and_start_threads(\n",
    "            cap, queues, process_config, results_dict, video_info\n",
    "        )\n",
    "        timestamps = self._join_threads(threads, self._post_process)\n",
    "\n",
    "        self._save_results(process_config['output_json_path'], results_dict)\n",
    "        self._save_timestamps(process_config['output_txt_path'], timestamps)\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "        print(f\"Video processing complete. {len(results_dict)} unique frames extracted.\")\n",
    "        print(f\"Output video saved to: {process_config['output_video_path']}\")\n",
    "        print(f\"Timestamps saved to: {process_config['output_txt_path']}\")\n",
    "        \n",
    "    def _save_timestamps(self, output_path: str, timestamps: List[str]):\n",
    "        with open(output_path, 'w') as f:\n",
    "            f.write('\\n'.join(timestamps))\n",
    "\n",
    "    def _join_threads(self, threads: List[Thread], \n",
    "                      post_process_func: Callable[[Queue, Queue], Any]) -> Any:\n",
    "        post_process_result = None\n",
    "        for thread in threads:\n",
    "            if thread._target == post_process_func:\n",
    "                post_process_result = thread.join()\n",
    "            else:\n",
    "                thread.join()\n",
    "        return post_process_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = 'output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_configs = [\n",
    "    {\n",
    "        'video_id': 'video1',\n",
    "        'input_path': 'data/videos/Rec16-1.mp4'\n",
    "    }\n",
    "]\n",
    "\n",
    "timestamp_region = (100, 831, 193, 865)\n",
    "ocr_processor = OCRProcessor(OUTPUT_DIR, timestamp_region, max_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-7 (_write_video):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/threading.py\", line 1073, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/prerak/IIIT/Tracking-and-counting-Using-YOLOv8-and-DeepSORT/work/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/usr/lib/python3.12/threading.py\", line 1010, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "TypeError: OCRProcessor._write_video() takes 4 positional arguments but 6 were given\n"
     ]
    }
   ],
   "source": [
    "ocr_processor.process_videos(video_configs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
