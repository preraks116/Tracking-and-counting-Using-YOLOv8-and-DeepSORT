{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.12.4\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ultralytics\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ultralytics\n",
    "import torch\n",
    "\n",
    "import cv2\n",
    "import time\n",
    "from queue import Queue\n",
    "from threading import Thread\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from abc import ABC, abstractmethod\n",
    "import json\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import threading\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Dict, Any, Tuple, Callable\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce GTX 1650'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_VIDEO_PATH = \"data/videos/Rec16-1_trimmed.mp4\"\n",
    "# OUTPUT_VIDEO_PATH = \"output/videos/Rec16-1-yolo_trimmed_final.mp4\"\n",
    "INPUT_TIMESTAMP_PATH = \"output/timestamps/Rec16-1_trimmed.txt\"\n",
    "# JSON_OUTPUT_PATH = \"output/json/Rec16-1_trimmed_yolo_final.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "YOLO_MODEL_PATH = \"models/yolo/yolov8n.pt\"\n",
    "YOLO_CONFIDENCE_THRESHOLD = 0.5\n",
    "MAX_QUEUE_SIZE = 30\n",
    "# Class indices for person, car, truck, bus, and motorcycle in COCO dataset\n",
    "TARGET_CLASSES = [0, 2, 7, 5, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FileIO:\n",
    "    @staticmethod\n",
    "    def read_lines(file_path):\n",
    "        with open(file_path, 'r') as f:\n",
    "            return [line.strip() for line in f]\n",
    "\n",
    "    @staticmethod\n",
    "    def read_json(file_path):\n",
    "        with open(file_path, 'r') as f:\n",
    "            return json.load(f)\n",
    "\n",
    "    @staticmethod\n",
    "    def write_json(file_path, data):\n",
    "        with open(file_path, 'w') as f:\n",
    "            json.dump(data, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoProcessor(ABC):\n",
    "    def __init__(self, output_dir, max_queue_size=MAX_QUEUE_SIZE, max_workers=None):\n",
    "        self.output_dir = output_dir\n",
    "        self.max_queue_size = max_queue_size\n",
    "        self.max_workers = max_workers\n",
    "        self.text_reader = FileIO()\n",
    "\n",
    "    @abstractmethod\n",
    "    def create_process_config(self, video_config):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def _process_frames(self, frame_queue, result_queue, process_config, results_dict):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def _post_process(self, result_queue, output_queue):\n",
    "        pass\n",
    "\n",
    "    def process_videos(self, video_configs):\n",
    "        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:\n",
    "            futures = [executor.submit(self.process_single_video, self.create_process_config(video_config)) \n",
    "                       for video_config in video_configs]\n",
    "            for future in as_completed(futures):\n",
    "                try:\n",
    "                    future.result()\n",
    "                except Exception as e:\n",
    "                    print(f\"An error occurred: {str(e)}\")\n",
    "\n",
    "    def process_single_video(self, process_config):\n",
    "        cap, video_params = self._initialize_video_capture(process_config['input_path'])\n",
    "        queues = self._create_queues()\n",
    "        results_dict = {}\n",
    "\n",
    "        threads = self._create_and_start_threads(cap, queues, process_config, results_dict, video_params)\n",
    "        self._join_threads(threads)\n",
    "        self._save_results(process_config['output_json_path'], results_dict)\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    def _initialize_video_capture(self, input_path):\n",
    "        cap = cv2.VideoCapture(input_path)\n",
    "        video_params = {\n",
    "            'width': int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
    "            'height': int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)),\n",
    "            'fps': int(cap.get(cv2.CAP_PROP_FPS))\n",
    "        }\n",
    "        return cap, video_params\n",
    "\n",
    "    def _create_queues(self):\n",
    "        return {name: Queue(maxsize=self.max_queue_size) for name in ['frame', 'result', 'output']}\n",
    "\n",
    "    def _create_and_start_threads(self, cap, queues, process_config, results_dict, video_params):\n",
    "        threads = [\n",
    "            Thread(target=self._read_frames, args=(cap, queues['frame'])),\n",
    "            Thread(target=self._process_frames, args=(queues['frame'], queues['result'], process_config, results_dict)),\n",
    "            Thread(target=self._post_process, args=(queues['result'], queues['output'])),\n",
    "            Thread(target=self._write_video, args=(process_config['output_video_path'], queues['output'], \n",
    "                                                   video_params['fps'], video_params['width'], video_params['height']))\n",
    "        ]\n",
    "        for thread in threads:\n",
    "            thread.start()\n",
    "        return threads\n",
    "\n",
    "    def _join_threads(self, threads):\n",
    "        for thread in threads:\n",
    "            thread.join()\n",
    "\n",
    "    def _save_results(self, output_json_path, results_dict):\n",
    "        self.text_reader.write_json(output_json_path, results_dict)\n",
    "\n",
    "    def _read_frames(self, cap, frame_queue):\n",
    "        while True:\n",
    "            if frame_queue.qsize() < self.max_queue_size:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                frame_queue.put(frame)\n",
    "            else:\n",
    "                time.sleep(0.1)\n",
    "        frame_queue.put(None)\n",
    "\n",
    "    def _write_video(self, output_path, output_queue, fps, width, height):\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "        \n",
    "        while True:\n",
    "            frame = output_queue.get()\n",
    "            if frame is None:\n",
    "                break\n",
    "            out.write(cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n",
    "        \n",
    "        out.release()\n",
    "\n",
    "    def get_unique_output_dir(self, base_path):\n",
    "        if not os.path.exists(base_path):\n",
    "            return base_path\n",
    "        \n",
    "        counter = 1\n",
    "        while True:\n",
    "            new_path = f\"{base_path}_copy{counter}\"\n",
    "            if not os.path.exists(new_path):\n",
    "                return new_path\n",
    "            counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "class GazeProcessor(VideoProcessor):\n",
    "    def __init__(self, output_dir: str, max_queue_size: int = MAX_QUEUE_SIZE, max_workers: int = None):\n",
    "        super().__init__(output_dir, max_queue_size, max_workers)\n",
    "\n",
    "    def create_process_config(self, video_config: dict) -> dict:\n",
    "        base_output_dir = os.path.join(self.output_dir, video_config['video_id'])\n",
    "        output_dir = self.get_unique_output_dir(base_output_dir)\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        return {\n",
    "            'input_path': video_config['input_path'],\n",
    "            'video_id': video_config['video_id'],\n",
    "            'output_dir': output_dir,\n",
    "            'output_json_path': os.path.join(output_dir, f\"{video_config['video_id']}_gaze.json\"),\n",
    "        }\n",
    "\n",
    "    def _process_frames(self, frame_queue: Queue, result_queue: Queue, process_config: dict, results_dict: dict):\n",
    "        frame_index = 0\n",
    "        while True:\n",
    "            frame = frame_queue.get()\n",
    "            if frame is None:\n",
    "                break\n",
    "\n",
    "            x, y, radius = self._get_circle_BB(frame)\n",
    "            \n",
    "            results_dict[frame_index] = {'x': x, 'y': y}\n",
    "            result_queue.put((frame_index, x, y))\n",
    "            frame_index += 1\n",
    "\n",
    "        result_queue.put(None)\n",
    "\n",
    "    def _post_process(self, result_queue: Queue, output_queue: Queue):\n",
    "        while True:\n",
    "            item = result_queue.get()\n",
    "            if item is None:\n",
    "                break\n",
    "\n",
    "    def _get_circle_BB(self, frame):\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        gray_blurred = cv2.blur(gray, (3, 3))\n",
    "        \n",
    "        detected_circles = cv2.HoughCircles(\n",
    "            gray_blurred, cv2.HOUGH_GRADIENT, 1, 20, \n",
    "            param1=50, param2=30, minRadius=18, maxRadius=19\n",
    "        )\n",
    "        \n",
    "        if detected_circles is None:\n",
    "            return 0.0, 0.0, 0.0\n",
    "\n",
    "        detected_circles = np.uint16(np.around(detected_circles))\n",
    "        x, y, r = map(float, detected_circles[0, 0])\n",
    "        return x, y, r\n",
    "\n",
    "    def _create_and_start_threads(self, cap, queues, process_config, results_dict, video_params):\n",
    "        threads = [\n",
    "            Thread(target=self._read_frames, args=(cap, queues['frame'])),\n",
    "            Thread(target=self._process_frames, args=(queues['frame'], queues['result'], process_config, results_dict)),\n",
    "            Thread(target=self._post_process, args=(queues['result'], queues['output']))\n",
    "        ]\n",
    "        for thread in threads:\n",
    "            thread.start()\n",
    "        return threads\n",
    "\n",
    "    def process_single_video(self, process_config: dict):\n",
    "        super().process_single_video(process_config)\n",
    "        print(f\"Gaze data saved to: {process_config['output_json_path']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_config = [\n",
    "    {\n",
    "        \"video_id\": \"balls\",\n",
    "        \"input_path\": INPUT_VIDEO_PATH,\n",
    "    },\n",
    "        {\n",
    "        \"video_id\": \"balls2\",\n",
    "        \"input_path\": INPUT_VIDEO_PATH,\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaze data saved to: output/gaze/balls/balls_gaze.json\n",
      "Gaze data saved to: output/gaze/balls2/balls2_gaze.json\n"
     ]
    }
   ],
   "source": [
    "gaze_processor = GazeProcessor(\"output/gaze\")\n",
    "\n",
    "gaze_processor.process_videos(video_config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
