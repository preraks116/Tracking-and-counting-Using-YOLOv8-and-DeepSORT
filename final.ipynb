{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ultralytics\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ultralytics\n",
    "import torch\n",
    "\n",
    "import cv2\n",
    "import time\n",
    "from queue import Queue\n",
    "from threading import Thread\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from abc import ABC, abstractmethod\n",
    "import json\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import threading\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Dict, Any, Tuple, Callable\n",
    "from collections import Counter\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['person', 'bicycle', 'car', 'motorcycle',\n",
    "               'airplane', 'bus', 'train', 'truck', 'boat',\n",
    "               'traffic light', 'fire hydrant', 'stop sign',\n",
    "               'parking meter', 'bench', 'bird', 'cat', 'dog',\n",
    "               'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra',\n",
    "               'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n",
    "               'suitcase', 'frisbee', 'skis', 'snowboard',\n",
    "               'sports ball', 'kite', 'baseball bat', 'baseball glove',\n",
    "               'skateboard', 'surfboard', 'tennis racket', 'bottle',\n",
    "               'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',\n",
    "               'banana', 'apple', 'sandwich', 'orange', 'broccoli',\n",
    "               'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair',\n",
    "               'couch', 'potted plant', 'bed', 'dining table', 'toilet',\n",
    "               'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
    "               'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book',\n",
    "               'clock', 'vase', 'scissors', 'teddy bear', 'hair drier',\n",
    "               'toothbrush']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "YOLO_MODEL_PATH = \"models/yolo/yolov8n.pt\"\n",
    "YOLO_CONFIDENCE_THRESHOLD = 0.5\n",
    "DEFAULT_QUEUE_SIZE = 30\n",
    "# Class indices for person, car, truck, bus, and motorcycle in COCO dataset\n",
    "TARGET_CLASSES = [0, 2, 7, 5, 3]\n",
    "DEFAULT_NUM_WORKERS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "YOLO_MODEL_PATH = \"models/yolo/yolov8n.pt\"\n",
    "YOLO_CONFIDENCE_THRESHOLD = 0.5\n",
    "MAX_QUEUE_SIZE = 30\n",
    "# Class indices for person, car, truck, bus, and motorcycle in COCO dataset\n",
    "TARGET_CLASSES = [0, 2, 7, 5, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEEP_SORT_MAX_AGE = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FileIO:\n",
    "    @staticmethod\n",
    "    def read_lines(file_path):\n",
    "        with open(file_path, 'r') as f:\n",
    "            return [line.strip() for line in f]\n",
    "\n",
    "    @staticmethod\n",
    "    def read_json(file_path):\n",
    "        with open(file_path, 'r') as f:\n",
    "            return json.load(f)\n",
    "\n",
    "    @staticmethod\n",
    "    def write_json(file_path, data):\n",
    "        with open(file_path, 'w') as f:\n",
    "            json.dump(data, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoProcessor(ABC):\n",
    "    def __init__(self, output_dir, max_queue_size=MAX_QUEUE_SIZE, max_workers=None):\n",
    "        self.output_dir = output_dir\n",
    "        self.max_queue_size = max_queue_size\n",
    "        self.max_workers = max_workers\n",
    "        self.text_reader = FileIO()\n",
    "\n",
    "    @abstractmethod\n",
    "    def create_process_config(self, video_config):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def _process_frames(self, frame_queue, result_queue, process_config, results_dict):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def _post_process(self, result_queue, output_queue):\n",
    "        pass\n",
    "\n",
    "    def process_videos(self, video_configs):\n",
    "        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:\n",
    "            futures = [executor.submit(self.process_single_video, self.create_process_config(video_config)) \n",
    "                       for video_config in video_configs]\n",
    "            for future in as_completed(futures):\n",
    "                try:\n",
    "                    future.result()\n",
    "                except Exception as e:\n",
    "                    print(f\"An error occurred: {str(e)}\")\n",
    "\n",
    "    def process_single_video(self, process_config):\n",
    "        cap, video_params = self._initialize_video_capture(process_config['input_path'])\n",
    "        queues = self._create_queues()\n",
    "        results_dict = {}\n",
    "\n",
    "        threads = self._create_and_start_threads(cap, queues, process_config, results_dict, video_params)\n",
    "        self._join_threads(threads)\n",
    "        self._save_results(process_config['output_json_path'], results_dict)\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    def _initialize_video_capture(self, input_path):\n",
    "        cap = cv2.VideoCapture(input_path)\n",
    "        video_params = {\n",
    "            'width': int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
    "            'height': int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)),\n",
    "            'fps': int(cap.get(cv2.CAP_PROP_FPS))\n",
    "        }\n",
    "        return cap, video_params\n",
    "\n",
    "    def _create_queues(self):\n",
    "        return {name: Queue(maxsize=self.max_queue_size) for name in ['frame', 'result', 'output']}\n",
    "\n",
    "    def _create_and_start_threads(self, cap, queues, process_config, results_dict, video_params):\n",
    "        threads = [\n",
    "            Thread(target=self._read_frames, args=(cap, queues['frame'])),\n",
    "            Thread(target=self._process_frames, args=(queues['frame'], queues['result'], process_config, results_dict)),\n",
    "            Thread(target=self._post_process, args=(queues['result'], queues['output'])),\n",
    "            Thread(target=self._write_video, args=(process_config['output_video_path'], queues['output'], \n",
    "                                                   video_params['fps'], video_params['width'], video_params['height']))\n",
    "        ]\n",
    "        for thread in threads:\n",
    "            thread.start()\n",
    "        return threads\n",
    "\n",
    "    def _join_threads(self, threads):\n",
    "        for thread in threads:\n",
    "            thread.join()\n",
    "\n",
    "    def _save_results(self, output_json_path, results_dict):\n",
    "        self.text_reader.write_json(output_json_path, results_dict)\n",
    "\n",
    "    def _read_frames(self, cap, frame_queue):\n",
    "        while True:\n",
    "            if frame_queue.qsize() < self.max_queue_size:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                frame_queue.put(frame)\n",
    "            else:\n",
    "                time.sleep(0.1)\n",
    "        frame_queue.put(None)\n",
    "\n",
    "    def _write_video(self, output_path, output_queue, fps, width, height):\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "        \n",
    "        while True:\n",
    "            frame = output_queue.get()\n",
    "            if frame is None:\n",
    "                break\n",
    "            out.write(cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n",
    "        \n",
    "        out.release()\n",
    "\n",
    "    def get_unique_output_dir(self, base_path):\n",
    "        if not os.path.exists(base_path):\n",
    "            return base_path\n",
    "        \n",
    "        counter = 1\n",
    "        while True:\n",
    "            new_path = f\"{base_path}_copy{counter}\"\n",
    "            if not os.path.exists(new_path):\n",
    "                return new_path\n",
    "            counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "class GazeProcessor(VideoProcessor):\n",
    "    def __init__(self, output_dir: str, max_queue_size: int = MAX_QUEUE_SIZE, max_workers: int = None):\n",
    "        super().__init__(output_dir, max_queue_size, max_workers)\n",
    "\n",
    "    def create_process_config(self, video_config: dict) -> dict:\n",
    "        base_output_dir = os.path.join(self.output_dir, video_config['video_id'])\n",
    "        output_dir = self.get_unique_output_dir(base_output_dir)\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        return {\n",
    "            'input_path': video_config['input_path'],\n",
    "            'video_id': video_config['video_id'],\n",
    "            'output_dir': output_dir,\n",
    "            'output_json_path': os.path.join(output_dir, f\"{video_config['video_id']}_gaze.json\"),\n",
    "        }\n",
    "\n",
    "    def _process_frames(self, frame_queue: Queue, result_queue: Queue, process_config: dict, results_dict: dict):\n",
    "        frame_index = 0\n",
    "        while True:\n",
    "            frame = frame_queue.get()\n",
    "            if frame is None:\n",
    "                break\n",
    "\n",
    "            x, y, radius = self._get_circle_BB(frame)\n",
    "            \n",
    "            results_dict[frame_index] = {'x': x, 'y': y}\n",
    "            result_queue.put((frame_index, x, y))\n",
    "            frame_index += 1\n",
    "\n",
    "        result_queue.put(None)\n",
    "\n",
    "    def _post_process(self, result_queue: Queue, output_queue: Queue):\n",
    "        while True:\n",
    "            item = result_queue.get()\n",
    "            if item is None:\n",
    "                break\n",
    "\n",
    "    def _get_circle_BB(self, frame):\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        gray_blurred = cv2.blur(gray, (3, 3))\n",
    "        \n",
    "        detected_circles = cv2.HoughCircles(\n",
    "            gray_blurred, cv2.HOUGH_GRADIENT, 1, 20, \n",
    "            param1=50, param2=30, minRadius=18, maxRadius=19\n",
    "        )\n",
    "        \n",
    "        if detected_circles is None:\n",
    "            return 0.0, 0.0, 0.0\n",
    "\n",
    "        detected_circles = np.uint16(np.around(detected_circles))\n",
    "        x, y, r = map(float, detected_circles[0, 0])\n",
    "        return x, y, r\n",
    "\n",
    "    def _create_and_start_threads(self, cap, queues, process_config, results_dict, video_params):\n",
    "        threads = [\n",
    "            Thread(target=self._read_frames, args=(cap, queues['frame'])),\n",
    "            Thread(target=self._process_frames, args=(queues['frame'], queues['result'], process_config, results_dict)),\n",
    "            Thread(target=self._post_process, args=(queues['result'], queues['output']))\n",
    "        ]\n",
    "        for thread in threads:\n",
    "            thread.start()\n",
    "        return threads\n",
    "\n",
    "    def process_single_video(self, process_config: dict):\n",
    "        super().process_single_video(process_config)\n",
    "        print(f\"Gaze data saved to: {process_config['output_json_path']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLOProcessor(VideoProcessor):\n",
    "    def __init__(self, output_dir, yolo_model_path=YOLO_MODEL_PATH, \n",
    "                 confidence_threshold=YOLO_CONFIDENCE_THRESHOLD, \n",
    "                 target_classes=TARGET_CLASSES,\n",
    "                 max_queue_size=MAX_QUEUE_SIZE, max_workers=None):\n",
    "        super().__init__(output_dir, max_queue_size, max_workers)\n",
    "        self.yolo_model = YOLO(yolo_model_path)\n",
    "        self.confidence_threshold = confidence_threshold\n",
    "        self.target_classes = target_classes\n",
    "\n",
    "    def create_process_config(self, video_config):\n",
    "        video_id = video_config['video_id']\n",
    "        output_dir = self.get_unique_output_dir(os.path.join(self.output_dir, video_id))\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        return {\n",
    "            'input_path': video_config['input_path'],\n",
    "            'video_id': video_id,\n",
    "            'gaze_path': video_config['gaze_path'],\n",
    "            'output_dir': output_dir,\n",
    "            'output_video_path': os.path.join(output_dir, f\"output_{video_id}.mp4\"),\n",
    "            'output_json_path': os.path.join(output_dir, f\"output_{video_id}.json\"),\n",
    "            'gaze': self.text_reader.read_json(video_config['gaze_path'])\n",
    "        }\n",
    "\n",
    "    def _process_frames(self, frame_queue, result_queue, process_config, results_dict):\n",
    "        frame_index = 0\n",
    "        # timestamps = process_config['timestamps']\n",
    "\n",
    "        while True:\n",
    "            frame = frame_queue.get()\n",
    "            if frame is None:\n",
    "                break\n",
    "            \n",
    "            results = self.yolo_model(frame, classes=self.target_classes, conf=self.confidence_threshold)\n",
    "            frame_results = []\n",
    "            gaze_target = None\n",
    "\n",
    "            # get gaze data for the current frame\n",
    "            gaze_data = process_config['gaze'][str(frame_index)]\n",
    "\n",
    "            for det in results[0].boxes.data:\n",
    "                x1, y1, x2, y2, conf, cls = det.tolist()\n",
    "                class_name = class_names[int(cls)]\n",
    "                bbox = [float(x1), float(y1), float(x2), float(y2)]  # Convert to float\n",
    "                \n",
    "                detect_data = {\n",
    "                    \"class\": class_name,\n",
    "                    \"confidence\": conf,\n",
    "                    \"bbox\": bbox\n",
    "                }\n",
    "                \n",
    "                frame_results.append(detect_data)\n",
    "                \n",
    "                # check if gaze point is within the bounding box\n",
    "                if gaze_data['x'] >= x1 and gaze_data['x'] <= x2 and gaze_data['y'] >= y1 and gaze_data['y'] <= y2:\n",
    "                    gaze_target = detect_data\n",
    "\n",
    "            # timestamp = timestamps[frame_index] if frame_index < len(timestamps) else f\"frame_{frame_index}\"\n",
    "            results_dict[frame_index] = {\n",
    "                \"detections\": frame_results,\n",
    "                \"gaze_target\": gaze_target\n",
    "            }\n",
    "            result_queue.put((frame, results))\n",
    "            frame_index += 1\n",
    "        \n",
    "        result_queue.put(None)\n",
    "\n",
    "    def _post_process(self, result_queue, output_queue):\n",
    "        while True:\n",
    "            item = result_queue.get()\n",
    "            if item is None:\n",
    "                break\n",
    "            frame, results = item\n",
    "            annotated_frame = results[0].plot()\n",
    "            output_queue.put(annotated_frame)\n",
    "        \n",
    "        output_queue.put(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAZE_OUTPUT_DIR = \"output/gaze\"\n",
    "YOLO_OUTPUT_DIR = \"output/yolo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gaze_config(video_list):\n",
    "    return [{'video_id': os.path.splitext(os.path.basename(video_path))[0], 'input_path': video_path} for video_path in video_list]\n",
    "\n",
    "def make_yolo_config(gaze_config):\n",
    "    for config in gaze_config:\n",
    "        video_id = config['video_id']\n",
    "        config['gaze_path'] = os.path.join(GAZE_OUTPUT_DIR, video_id, f\"{video_id}_gaze.json\")\n",
    "    return gaze_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_list = [\n",
    "    \"data/videos/Rec16-1_trimmed.mp4\",\n",
    "    \"data/videos/Rec16-1_trimmed.mp4\"\n",
    "]\n",
    "\n",
    "gaze_config = make_gaze_config(video_list)\n",
    "yolo_config = make_yolo_config(gaze_config)\n",
    "print(gaze_config)\n",
    "print(yolo_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gaze_processor = GazeProcessor(GAZE_OUTPUT_DIR)\n",
    "\n",
    "# gaze_processor.process_videos(gaze_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yolo_processor = YOLOProcessor(YOLO_OUTPUT_DIR, max_workers=DEFAULT_NUM_WORKERS)\n",
    "\n",
    "# yolo_processor.process_videos(yolo_config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
